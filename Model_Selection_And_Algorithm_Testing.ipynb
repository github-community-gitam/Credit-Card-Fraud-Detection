{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Model** **Selection** **and** **Algorithm** **Testing**"
      ],
      "metadata": {
        "id": "xrkegmh4lyT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "8gSqQ8xgBHNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('cleaned_fraud_data.csv')"
      ],
      "metadata": {
        "id": "1DmeAnKQmfhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare features (X) and target (y)\n",
        "X = df.drop(columns=['trans_date_trans_time', 'dob', 'is_fraud'])"
      ],
      "metadata": {
        "id": "8AbUmx6TmhHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handle categorical columns using one-hot encoding\n",
        "categorical_columns = ['category', 'gender', 'job_sector', 'Region', 'age_group', 'day_period']"
      ],
      "metadata": {
        "id": "BJYJ2uQltVtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target column\n",
        "y = df['is_fraud']"
      ],
      "metadata": {
        "id": "KRmsFeQZvN_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "Yfz1pVRhvszc",
        "outputId": "8ec19c79-38ef-4c57-fee8-d0ef2e4f20ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "is_fraud\n",
              "0    1042569\n",
              "1       6006\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_fraud</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1042569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "r6fa4snCmqOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "127fICPimDOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the feature data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "ScKosmltvdEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the size of each group\n",
        "fraud_df = df[df['is_fraud'] == 1]\n",
        "no_fraud_df = df[df['is_fraud'] == 0]\n",
        "fraud_count = len(fraud_df)\n",
        "no_fraud_count = len(no_fraud_df)\n",
        "\n",
        "# Print counts for debugging\n",
        "print(f\"Fraud cases: {fraud_count}, No Fraud cases: {no_fraud_count}\")\n",
        "\n",
        "# Adjust n if needed\n",
        "fraud_subset_size = min(7000, fraud_count)\n",
        "no_fraud_subset_size = min(10000, no_fraud_count)\n",
        "\n",
        "# Sampling from fraud and no fraud subsets\n",
        "fraud_subset = fraud_df.sample(n=fraud_subset_size, random_state=42, replace=False)\n",
        "no_fraud_subset = no_fraud_df.sample(n=no_fraud_subset_size, random_state=42, replace=False)\n",
        "\n",
        "# Combine the subsets\n",
        "new_df = pd.concat([fraud_subset, no_fraud_subset])\n",
        "\n",
        "# Reset index of the new dataframe\n",
        "new_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Assign the balanced dataframe back to df\n",
        "df = new_df\n"
      ],
      "metadata": {
        "id": "CPi4L4w2rCm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a8a1897-c207-48e1-ea7d-e476421b0b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fraud cases: 6006, No Fraud cases: 1042569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression**"
      ],
      "metadata": {
        "id": "xAAdO39EmIyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "# Logistic Regression Model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lr = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr)\n",
        "recall_lr = recall_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"Logistic Regression - Accuracy: {accuracy_lr}, Precision: {precision_lr}, Recall: {recall_lr}, F1-Score: {f1_lr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFTvaENCm1Ch",
        "outputId": "774130e3-e98d-43d4-9d1f-5d918c88a088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.9939203204348759, Precision: 0.0, Recall: 0.0, F1-Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model demonstrates high accuracy due to class imbalance but fails to effectively predict fraud cases, leading to 0 for precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "ZNSPo7MsvzSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "dI1mAtXLqT04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Decision Tree Model\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_dt = decision_tree.predict(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "f1_dt = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "print(f\"Decision Tree - Accuracy: {accuracy_dt}, Precision: {precision_dt}, Recall: {recall_dt}, F1-Score: {f1_dt}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig_zyBPgm44C",
        "outputId": "d311cda3-ac0f-4799-b2a7-1ca301c8a45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - Accuracy: 0.9970197649190569, Precision: 0.7245557350565428, Recall: 0.7595258255715496, F1-Score: 0.7416287722199256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decision Tree model achieved a high accuracy of about 99.69%, indicating it effectively identifies most transactions correctly.he F1-score of about 73.99% suggests a good balance between precision and recall, making the Decision Tree a reliable choice for detecting credit card fraud."
      ],
      "metadata": {
        "id": "fYxxwdykwyzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "sr1tf-xn51AC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Model 3: Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=50,max_depth=10,class_weight='balanced', random_state=42)\n",
        "rf.fit(X_train,y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Evaluation metrics for Random Forest\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf)\n",
        "recall_rf = recall_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf)\n",
        "print(f\"Random Forest - Accuracy: {accuracy_rf:.4f}, Precision: {precision_rf:.4f}, Recall: {recall_rf:.4f}, F1-Score: {f1_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d6XsDZpuS4J",
        "outputId": "c81988ec-2160-4836-9631-81241bcda02e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Accuracy: 0.9982, Precision: 0.9318, Recall: 0.7290, F1-Score: 0.8181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest model achieves a high accuracy of 99.82% and strong precision of 93.18%, indicating it correctly identifies most transactions while minimizing false positives. However, its recall of 72.90% shows it misses some fraud cases. Overall, with an F1-score of 81.81%, it provides a reliable performance for credit card fraud detection."
      ],
      "metadata": {
        "id": "gg_DXNBqyNsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Machine(SVM)**"
      ],
      "metadata": {
        "id": "16QjEJv657Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVC  # Faster alternative to SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Subset the data for faster initial testing\n",
        "X_train_scaled_subset = X_train_scaled[:1000]\n",
        "y_train_subset = y_train[:1000]\n",
        "\n",
        "#Hyperparameter tuning with RandomizedSearchCV\n",
        "param_distributions = {'C': [0.1, 1, 10]}\n",
        "svm_model = LinearSVC(random_state=42)\n",
        "\n",
        "random_search = RandomizedSearchCV(svm_model, param_distributions, n_iter=3, cv=2, random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train_scaled_subset, y_train_subset)\n",
        "\n",
        "\n",
        "best_svm_model = random_search.best_estimator_\n",
        "\n",
        "\n",
        "y_pred_svm = best_svm_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "\n",
        "\n",
        "print(f\"SVM (Tuned) - Accuracy: {accuracy_svm}, Precision: {precision_svm}, Recall: {recall_svm}, F1-Score: {f1_svm}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Q5-kIv-xYGwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17072c4-299c-4921-a83c-52b8ba82db69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM (Tuned) - Accuracy: 0.9935722289774217, Precision: 0.0, Recall: 0.0, F1-Score: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The low precision, recall, and F1-score indicate that the SVM model is likely predicting only the majority class (no fraud) and not detecting the minority class (fraud)."
      ],
      "metadata": {
        "id": "rEQZTwV5mqD1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n"
      ],
      "metadata": {
        "id": "xrSnELRQf6K3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying different models on the dataset, we find that Random Forest is the best model for Credit Card Fraud Detection. It has the following metrics:\n",
        "\n",
        "\n",
        "\n",
        "*  Accuracy: 0.9982\n",
        "*  Precision: 0.9318\n",
        "*  Recall: 0.7290\n",
        "*  F1-Score: 0.8181\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The Random Forest model achieves a high accuracy of 99.82% and strong precision of 93.18%, indicating it correctly identifies most transactions while minimizing false positives. However, its recall of 72.90% shows it misses some fraud cases. Overall, with an F1-score of 81.81%, it provides a reliable performance for credit card fraud detection."
      ],
      "metadata": {
        "id": "c9H2cUBKf_WF"
      }
    }
  ]
}